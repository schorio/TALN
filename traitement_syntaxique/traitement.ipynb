{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les contenus d'un fichier texte\n",
    "\n",
    "t_txt = open('texte.txt', \"r\")\n",
    "Text_txt = t_txt.read()\n",
    "text_txt = (Text_txt).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'boy', 'with', 'fair', 'hair', 'lowered', 'himself', 'down', 'the', 'last', 'few', 'feet', 'of', 'rock', 'and', 'began', 'to', 'pick', 'his', 'way', 'toward', 'the', 'lagoon', '.', 'though', 'he', 'had', 'taken', 'off', 'his', 'school', 'sweater', 'and', 'trailed', 'it', 'now', 'from', 'one', 'hand', ',', 'his', 'grey', 'shirt', 'stuck', 'to', 'him', 'and', 'his', 'hair', 'was', 'plastered', 'to', 'his', 'forehead', '.', 'all', 'round', 'him', 'the', 'long', 'scar', 'smashed', 'into', 'the', 'jungle', 'was', 'a', 'bath', 'of', 'heat', '.', 'he', 'was', 'clambering', 'heavily', 'among', 'the', 'creepers', 'and', 'broken', 'trunks', 'when', 'a', 'bird', ',', 'a', 'vision', 'of', 'red', 'and', 'yellow', ',', 'flashed', 'upwards', 'with', 'a', 'witch-like', 'cry', ';', 'and', 'this', 'cry', 'was', 'echoed', 'by', 'another', '.']\n",
      "107\n"
     ]
    }
   ],
   "source": [
    "# Tokenisation\n",
    "tokens = nltk.word_tokenize(text_txt)\n",
    "# tokens = [token for token in tokens if token not in stop_words]\n",
    "print(tokens)\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supression du caractere speciaux de chaque mot du tableau\n",
    "mots = []\n",
    "for j in tokens:\n",
    "    text = re.sub(r\"[^a-zA-Zéèçêù$âäëöôüû]\",\"\",j)\n",
    "    mots.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supression des emplacement libre dans le tableau\n",
    "liste_mots = list(filter(lambda x: x!=\"\",mots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " le nb de mot trouver :  99\n"
     ]
    }
   ],
   "source": [
    "# Afficher le nombre de mot touver\n",
    "print(\"\\n le nb de mot trouver : \" , len(liste_mots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "\n",
    "mots_tagger = pos_tag(liste_mots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "noms = [word for word, pos in mots_tagger if pos in ['NN']]\n",
    "noms_p = [word for word, pos in mots_tagger if pos in ['NNP']]\n",
    "verbes = [word for word, pos in mots_tagger if pos in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']]\n",
    "determinants = [word for word, pos in mots_tagger if pos == 'DT']\n",
    "prepositions = [word for word, pos in mots_tagger if pos == 'IN']\n",
    "adjectives = [word for word, tag in mots_tagger if tag == 'JJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les doublons dans la liste contenant les noms et les verbes\n",
    "noms = list(set(noms))\n",
    "noms_p = list(set(noms_p))\n",
    "verbes = list(set(verbes))\n",
    "determinants = list(set(determinants))\n",
    "prepositions = list(set(prepositions))\n",
    "adjectives = list(set(adjectives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"school\" | \"vision\" | \"cry\" | \"hand\" | \"hair\" | \"way\" | \"grey\" | \"jungle\" | \"bird\" | \"sweater\" | \"boy\" | \"lagoon\" | \"bath\" | \"forehead\" | \"heat\" | \"witchlike\" | \"scar\" | \"rock\"\n",
      "18\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Construisez la partie de la règle NP qui contient tous les noms\n",
    "liste_noms = ' | '.join(f'\"{n}\"' for n in noms)\n",
    "print(liste_noms)\n",
    "print(len(noms))\n",
    "liste_noms_p = ' | '.join(f'\"{n}\"' for n in noms_p)\n",
    "print(liste_noms_p)\n",
    "print(len(noms_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"smashed\" | \"plastered\" | \"shirt\" | \"was\" | \"flashed\" | \"clambering\" | \"echoed\" | \"trailed\" | \"lowered\" | \"taken\" | \"began\" | \"stuck\" | \"round\" | \"had\" | \"pick\"\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# Construisez la partie de la règle NP qui contient tous les verbes\n",
    "liste_verbes = ' | '.join(f'\"{v}\"' for v in verbes)\n",
    "print(liste_verbes)\n",
    "print(len(verbes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"a\" | \"another\" | \"all\" | \"the\" | \"this\"\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Construisez la partie de la règle NP qui contient tous les determinants\n",
    "liste_determinants = ' | '.join(f'\"{n}\"' for n in determinants)\n",
    "print(liste_determinants)\n",
    "print(len(determinants))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
