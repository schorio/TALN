{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les contenus d'un fichier texte\n",
    "\n",
    "t_txt = open('texte.txt', \"r\")\n",
    "Text_txt = t_txt.read()\n",
    "text_txt = (Text_txt).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'boy', 'with', 'fair', 'hair', 'lowered', 'himself', 'down', 'the', 'last', 'few', 'feet', 'of', 'rock', 'and', 'began', 'to', 'pick', 'his', 'way', 'toward', 'the', 'lagoon', '.', 'though', 'he', 'had', 'taken', 'off', 'his', 'school', 'sweater', 'and', 'trailed', 'it', 'now', 'from', 'one', 'hand', ',', 'his', 'grey', 'shirt', 'stuck', 'to', 'him', 'and', 'his', 'hair', 'was', 'plastered', 'to', 'his', 'forehead', '.', 'all', 'round', 'him', 'the', 'long', 'scar', 'smashed', 'into', 'the', 'jungle', 'was', 'a', 'bath', 'of', 'heat', '.', 'he', 'was', 'clambering', 'heavily', 'among', 'the', 'creepers', 'and', 'broken', 'trunks', 'when', 'a', 'bird', ',', 'a', 'vision', 'of', 'red', 'and', 'yellow', ',', 'flashed', 'upwards', 'with', 'a', 'witch-like', 'cry', ';', 'and', 'this', 'cry', 'was', 'echoed', 'by', 'another', '.']\n",
      "107\n"
     ]
    }
   ],
   "source": [
    "# Tokenisation\n",
    "tokens = nltk.word_tokenize(text_txt)\n",
    "# tokens = [token for token in tokens if token not in stop_words]\n",
    "print(tokens)\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supression du caractere speciaux de chaque mot du tableau\n",
    "mots = []\n",
    "for j in tokens:\n",
    "    text = re.sub(r\"[^a-zA-Zéèçêù$âäëöôüû]\",\"\",j)\n",
    "    mots.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supression des emplacement libre dans le tableau\n",
    "liste_mots = list(filter(lambda x: x!=\"\",mots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " le nb de mot trouver :  99\n"
     ]
    }
   ],
   "source": [
    "# Afficher le nombre de mot touver\n",
    "print(\"\\n le nb de mot trouver : \" , len(liste_mots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "\n",
    "mots_tagger = pos_tag(liste_mots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "noms = [word for word, pos in mots_tagger if pos in ['NN']]\n",
    "noms_p = [word for word, pos in mots_tagger if pos in ['NNP']]\n",
    "verbes = [word for word, pos in mots_tagger if pos in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']]\n",
    "determinants = [word for word, pos in mots_tagger if pos == 'DT']\n",
    "prepositions = [word for word, pos in mots_tagger if pos == 'IN']\n",
    "adjectives = [word for word, tag in mots_tagger if tag == 'JJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les doublons dans la liste contenant les noms et les verbes\n",
    "noms = list(set(noms))\n",
    "noms_p = list(set(noms_p))\n",
    "verbes = list(set(verbes))\n",
    "determinants = list(set(determinants))\n",
    "prepositions = list(set(prepositions))\n",
    "adjectives = list(set(adjectives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"bird\" | \"jungle\" | \"boy\" | \"cry\" | \"sweater\" | \"witchlike\" | \"rock\" | \"bath\" | \"forehead\" | \"lagoon\" | \"grey\" | \"hand\" | \"scar\" | \"heat\" | \"vision\" | \"hair\" | \"school\" | \"way\"\n",
      "18\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Construisez la partie de la règle NP qui contient tous les noms\n",
    "liste_noms = ' | '.join(f'\"{n}\"' for n in noms)\n",
    "print(liste_noms)\n",
    "print(len(noms))\n",
    "liste_noms_p = ' | '.join(f'\"{n}\"' for n in noms_p)\n",
    "print(liste_noms_p)\n",
    "print(len(noms_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"pick\" | \"flashed\" | \"round\" | \"trailed\" | \"had\" | \"smashed\" | \"began\" | \"stuck\" | \"plastered\" | \"was\" | \"lowered\" | \"taken\" | \"clambering\" | \"echoed\" | \"shirt\"\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# Construisez la partie de la règle NP qui contient tous les verbes\n",
    "liste_verbes = ' | '.join(f'\"{v}\"' for v in verbes)\n",
    "print(liste_verbes)\n",
    "print(len(verbes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"all\" | \"this\" | \"the\" | \"a\" | \"another\"\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Construisez la partie de la règle NP qui contient tous les determinants\n",
    "liste_determinants = ' | '.join(f'\"{n}\"' for n in determinants)\n",
    "print(liste_determinants)\n",
    "print(len(determinants))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"with\" | \"toward\" | \"from\" | \"into\" | \"though\" | \"among\" | \"by\" | \"of\"\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# Construisez la partie de la règle NP qui contient tous les prepositions\n",
    "liste_prepositions = ' | '.join(f'\"{n}\"' for n in prepositions)\n",
    "print(liste_prepositions)\n",
    "print(len(prepositions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"yellow\" | \"fair\" | \"long\" | \"few\" | \"broken\" | \"last\" | \"red\"\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# Construisez la partie de la règle NP qui contient tous les adjectives\n",
    "liste_adjectives = ' | '.join(f'\"{n}\"' for n in adjectives)\n",
    "print(liste_adjectives)\n",
    "print(len(adjectives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Grammar with 64 productions>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import CFG\n",
    "\n",
    "# Construisez la grammaire complète en incluant la nouvelle règle NP\n",
    "grammar1 = CFG.fromstring(f\"\"\"\n",
    "    S -> NP V | NP VP\n",
    "    VP -> V NP | V NP PP\n",
    "    PP -> P | P NP\n",
    "    V -> {liste_verbes}\n",
    "    NP -> {liste_noms_p} | N | J N | Det N | Det N PP\n",
    "    Det -> {liste_determinants}\n",
    "    N -> {liste_noms}\n",
    "    P -> {liste_prepositions}\n",
    "    J -> {liste_adjectives}\n",
    "\"\"\")\n",
    "\n",
    "grammar1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
