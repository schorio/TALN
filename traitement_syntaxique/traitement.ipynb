{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les contenus d'un fichier texte\n",
    "\n",
    "t_txt = open('texte.txt', \"r\")\n",
    "Text_txt = t_txt.read()\n",
    "text_txt = (Text_txt).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'boy', 'with', 'fair', 'hair', 'lowered', 'himself', 'down', 'the', 'last', 'few', 'feet', 'of', 'rock', 'and', 'began', 'to', 'pick', 'his', 'way', 'toward', 'the', 'lagoon', '.', 'though', 'he', 'had', 'taken', 'off', 'his', 'school', 'sweater', 'and', 'trailed', 'it', 'now', 'from', 'one', 'hand', ',', 'his', 'grey', 'shirt', 'stuck', 'to', 'him', 'and', 'his', 'hair', 'was', 'plastered', 'to', 'his', 'forehead', '.', 'all', 'round', 'him', 'the', 'long', 'scar', 'smashed', 'into', 'the', 'jungle', 'was', 'a', 'bath', 'of', 'heat', '.', 'he', 'was', 'clambering', 'heavily', 'among', 'the', 'creepers', 'and', 'broken', 'trunks', 'when', 'a', 'bird', ',', 'a', 'vision', 'of', 'red', 'and', 'yellow', ',', 'flashed', 'upwards', 'with', 'a', 'witch-like', 'cry', ';', 'and', 'this', 'cry', 'was', 'echoed', 'by', 'another', '.']\n",
      "107\n"
     ]
    }
   ],
   "source": [
    "# Tokenisation\n",
    "tokens = nltk.word_tokenize(text_txt)\n",
    "# tokens = [token for token in tokens if token not in stop_words]\n",
    "print(tokens)\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m mots \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m tokens:\n\u001b[0;32m----> 4\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[^a-zA-Zéèçêù$âäëöôüû]\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,j)\n\u001b[1;32m      5\u001b[0m     mots\u001b[38;5;241m.\u001b[39mappend(text)\n",
      "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "# supression du caractere speciaux de chaque mot du tableau\n",
    "mots = []\n",
    "for j in tokens:\n",
    "    text = re.sub(r\"[^a-zA-Zéèçêù$âäëöôüû]\",\"\",j)\n",
    "    mots.append(text)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
